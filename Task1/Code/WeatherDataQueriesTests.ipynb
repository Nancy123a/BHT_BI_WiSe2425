{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the necessary weather data from the given .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports -- change ip and fingerprint between hosts\n",
    "import pandas as pd\n",
    "import pyexasol\n",
    "\n",
    "host = ''   # Don't forget to change the fingerprint\n",
    "user = 'sys'\n",
    "password = 'exasol'\n",
    "\n",
    "# Connect to Exasol\n",
    "conn = pyexasol.connect(dsn=host, \n",
    "                        user=user, \n",
    "                        password=password, \n",
    "                        debug=False, \n",
    "                        protocol_version=pyexasol.PROTOCOL_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48595, 58)\n",
      "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
      "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
      "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
      "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
      "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
      "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
      "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
      "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
      "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
      "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'LAST_MOD_DATE',\n",
      "       'LAST_MOD_TIME', 'LAST_CERT_DATE', 'LAST_CERT_TIME', 'LAST_MOD',\n",
      "       'LAST_CERT', 'ADDCORR_FLG', 'ADDCORR_DATE'],\n",
      "      dtype='object')\n",
      "(48595, 58)\n",
      "min: 2006-01-01 00:00:00 \n",
      "max: 2006-10-27 21:00:00\n",
      "(25734, 58)\n",
      "min: 2006-01-01 00:00:00 \n",
      "max: 2006-05-31 23:59:00\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./../Data/Stormdata_2006.csv', encoding='iso-8859-1')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# Convert start and end dates to date time\n",
    "df['END_DATE_TIME'] = pd.to_datetime(df['END_DATE_TIME'])\n",
    "df['BEGIN_DATE_TIME'] = pd.to_datetime(df['BEGIN_DATE_TIME'])\n",
    "\n",
    "print(df.shape)\n",
    "print(\"min:\", min(df['BEGIN_DATE_TIME']), \"\\nmax:\", max(df['END_DATE_TIME']))\n",
    "\n",
    "# Remove those ending after our AOL database - Those before could be ok?\n",
    "df = df[df['END_DATE_TIME'] <= '2006-06-01 00:00:00']\n",
    "\n",
    "print(df.shape)\n",
    "print(\"min:\", min(df['BEGIN_DATE_TIME']), \"\\nmax:\", max(df['END_DATE_TIME']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BEGIN_DATE_TIME', 'END_DATE_TIME', 'EVENT_TYPE', 'BEGIN_DAY',\n",
      "       'END_DAY', 'BEGIN_YEARMONTH', 'END_YEARMONTH', 'STATE', 'STATE_FIPS',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'EPISODE_ID',\n",
      "       'EVENT_ID'],\n",
      "      dtype='object')\n",
      "<bound method NDFrame.head of           BEGIN_DATE_TIME       END_DATE_TIME                EVENT_TYPE  \\\n",
      "0     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "1     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "2     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "3     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "4     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "...                   ...                 ...                       ...   \n",
      "25729 2006-05-31 21:10:00 2006-05-31 22:15:00  Marine Thunderstorm Wind   \n",
      "25730 2006-05-31 22:00:00 2006-05-31 22:00:00         Thunderstorm Wind   \n",
      "25731 2006-05-31 22:05:00 2006-05-31 22:05:00         Thunderstorm Wind   \n",
      "25732 2006-05-31 23:05:00 2006-05-31 23:05:00         Thunderstorm Wind   \n",
      "25733 2006-05-31 23:45:00 2006-05-31 23:59:00               Flash Flood   \n",
      "\n",
      "       BEGIN_DAY  END_DAY  BEGIN_YEARMONTH  END_YEARMONTH          STATE  \\\n",
      "0              1       31           200601         200601       COLORADO   \n",
      "1              1       31           200601         200601          TEXAS   \n",
      "2              1       31           200601         200601          TEXAS   \n",
      "3              1       31           200601         200601       OKLAHOMA   \n",
      "4              1       31           200601         200601       OKLAHOMA   \n",
      "...          ...      ...              ...            ...            ...   \n",
      "25729         31       31           200605         200605      LAKE ERIE   \n",
      "25730         31       31           200605         200605       NEW YORK   \n",
      "25731         31       31           200605         200605           OHIO   \n",
      "25732         31       31           200605         200605  WEST VIRGINIA   \n",
      "25733         31       31           200605         200605          TEXAS   \n",
      "\n",
      "       STATE_FIPS  INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  \\\n",
      "0               8                0                  0              0   \n",
      "1              48                0                  0              0   \n",
      "2              48                0                  0              0   \n",
      "3              40                0                  0              0   \n",
      "4              40                0                  0              0   \n",
      "...           ...              ...                ...            ...   \n",
      "25729          95                0                  0              0   \n",
      "25730          36                0                  0              0   \n",
      "25731          39                0                  0              0   \n",
      "25732          54                0                  0              0   \n",
      "25733          48                0                  0              0   \n",
      "\n",
      "       DEATHS_INDIRECT DAMAGE_PROPERTY DAMAGE_CROPS  EPISODE_ID  EVENT_ID  \n",
      "0                    0             NaN          NaN      202408   5482479  \n",
      "1                    0             NaN          NaN      203632   5486559  \n",
      "2                    0             NaN          NaN      203632   5486558  \n",
      "3                    0             NaN          NaN      203694   5486086  \n",
      "4                    0             NaN          NaN      203694   5486085  \n",
      "...                ...             ...          ...         ...       ...  \n",
      "25729                0             NaN          NaN      211946   5512620  \n",
      "25730                0             NaN          NaN      209876   5505143  \n",
      "25731                0              6K          NaN      211942   5512434  \n",
      "25732                0             NaN          NaN      206999   5497477  \n",
      "25733                0             NaN          NaN      211953   5512881  \n",
      "\n",
      "[25734 rows x 17 columns]>\n",
      "Index(['BEGIN_DATE_TIME', 'END_DATE_TIME', 'EVENT_TYPE', 'BEGIN_DAY',\n",
      "       'END_DAY', 'STATE_FIPS', 'INJURIES_DIRECT', 'INJURIES_INDIRECT',\n",
      "       'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS',\n",
      "       'EPISODE_ID', 'EVENT_ID', 'BEGIN_MONTH', 'END_MONTH', 'REGION'],\n",
      "      dtype='object')\n",
      "<bound method NDFrame.head of           BEGIN_DATE_TIME       END_DATE_TIME                EVENT_TYPE  \\\n",
      "0     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "1     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "2     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "3     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "4     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "...                   ...                 ...                       ...   \n",
      "25729 2006-05-31 21:10:00 2006-05-31 22:15:00  Marine Thunderstorm Wind   \n",
      "25730 2006-05-31 22:00:00 2006-05-31 22:00:00         Thunderstorm Wind   \n",
      "25731 2006-05-31 22:05:00 2006-05-31 22:05:00         Thunderstorm Wind   \n",
      "25732 2006-05-31 23:05:00 2006-05-31 23:05:00         Thunderstorm Wind   \n",
      "25733 2006-05-31 23:45:00 2006-05-31 23:59:00               Flash Flood   \n",
      "\n",
      "       BEGIN_DAY  END_DAY  STATE_FIPS  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
      "0              1       31           8                0                  0   \n",
      "1              1       31          48                0                  0   \n",
      "2              1       31          48                0                  0   \n",
      "3              1       31          40                0                  0   \n",
      "4              1       31          40                0                  0   \n",
      "...          ...      ...         ...              ...                ...   \n",
      "25729         31       31          95                0                  0   \n",
      "25730         31       31          36                0                  0   \n",
      "25731         31       31          39                0                  0   \n",
      "25732         31       31          54                0                  0   \n",
      "25733         31       31          48                0                  0   \n",
      "\n",
      "       DEATHS_DIRECT  DEATHS_INDIRECT DAMAGE_PROPERTY DAMAGE_CROPS  \\\n",
      "0                  0                0             NaN          NaN   \n",
      "1                  0                0             NaN          NaN   \n",
      "2                  0                0             NaN          NaN   \n",
      "3                  0                0             NaN          NaN   \n",
      "4                  0                0             NaN          NaN   \n",
      "...              ...              ...             ...          ...   \n",
      "25729              0                0             NaN          NaN   \n",
      "25730              0                0             NaN          NaN   \n",
      "25731              0                0              6K          NaN   \n",
      "25732              0                0             NaN          NaN   \n",
      "25733              0                0             NaN          NaN   \n",
      "\n",
      "       EPISODE_ID  EVENT_ID  BEGIN_MONTH  END_MONTH         REGION  \n",
      "0          202408   5482479            1          1       Colorado  \n",
      "1          203632   5486559            1          1          Texas  \n",
      "2          203632   5486558            1          1          Texas  \n",
      "3          203694   5486086            1          1       Oklahoma  \n",
      "4          203694   5486085            1          1       Oklahoma  \n",
      "...           ...       ...          ...        ...            ...  \n",
      "25729      211946   5512620            5          5      Lake erie  \n",
      "25730      209876   5505143            5          5       New york  \n",
      "25731      211942   5512434            5          5           Ohio  \n",
      "25732      206999   5497477            5          5  West virginia  \n",
      "25733      211953   5512881            5          5          Texas  \n",
      "\n",
      "[25734 rows x 17 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Keep: 'BEGIN_DATE_TIME', 'END_DATE_TIME', 'EVENT_TYPE', 'BEGIN_DAY', 'END_DAY', 'BEGIN_YEARMONTH', 'END_YEARMONTH', 'STATE', 'STATE_FIPS', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS' \n",
    "keep = ['BEGIN_DATE_TIME', 'END_DATE_TIME', 'EVENT_TYPE', 'BEGIN_DAY', 'END_DAY', 'BEGIN_YEARMONTH', 'END_YEARMONTH', 'STATE', 'STATE_FIPS', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'EPISODE_ID', 'EVENT_ID']\n",
    "\n",
    "df = df.loc[:, keep]\n",
    "\n",
    "print(df.columns)\n",
    "print(df.head)\n",
    "\n",
    "# Fix year/month and naming oddness\n",
    "df['BEGIN_MONTH'] = df['BEGIN_YEARMONTH'] - 200600\n",
    "df['END_MONTH'] = df['END_YEARMONTH'] - 200600\n",
    "df['REGION'] = df['STATE'].str[0].str.upper() + df['STATE'].str[1:].str.lower() # This contains all the spatial information we need- writing the state name was buggy\n",
    "df['EVENT_TYPE'] = df['EVENT_TYPE'].astype(str)\n",
    "\n",
    "df = df.drop(columns= ['BEGIN_YEARMONTH', 'END_YEARMONTH', 'STATE'])\n",
    "\n",
    "print(df.columns)\n",
    "print(df.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the damage cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_abbreviated_string(value):\n",
    "    # Check for 'k' (thousand), 'm' (million), 'b' (billion)\n",
    "    if isinstance(value, str):\n",
    "        print(value)\n",
    "        if 'k' in value.lower():\n",
    "            return float(value.replace('k', '').replace('K', '')) * 1000\n",
    "        elif 'm' in value.lower():\n",
    "            return float(value.replace('m', '').replace('M', '')) * 1000000\n",
    "        elif 'b' in value.lower():\n",
    "            return float(value.replace('b', '').replace('B', '')) * 1000000000\n",
    "        else:\n",
    "            # If no abbreviation, just return the float version of the number\n",
    "            try:\n",
    "                return float(value)\n",
    "            except ValueError:\n",
    "                return None  # or handle invalid strings as needed\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['900K' '4.9M' '2M' '3.2M' '4.5M' '700K' '100K' '1M' '15M' '165K' '243K'\n",
      " '524K' '623K' '1.2M' '5M' '115B' '104M' '0' '22M' '2.5M' '8.8M' '108M'\n",
      " '70K' '20K' '50K' '35K' '36K' '87K' '15K' '175K' '0K' '500K' '200K'\n",
      " '800K' '1K' '10K' '2K' '25K' '71K' '1.4M' '5.5M' '.1K' '75K' '5K' '45K'\n",
      " '55K' '.5K' '3K' '750K' '4M' '250K' '150K' '350K' '8K' '300K' '400K' '7K'\n",
      " '12K' '80K' '2.9M' '600K' '130K' '30K' '90K' '450K' '4K' '1.5K' '65K'\n",
      " '60K' '40K' '.25M' '120K' '.1M' '.5M' '160K' '16K' '2.5K' '.05K' '81K'\n",
      " '9K' '7.5M' '230K' '125K' '94.5K' '380K' '14K' '1.6M' '6K' '4.5K' '.01K'\n",
      " '1.5M' '85K' '11K' '168K' '357K' '.2K' '.25K' '10M' '.21K' '.17K' '8M'\n",
      " '19.9M' '30M' '3M' '850K' '50M' '650K' '3.5K' '126K' '265K' '.86K' '27K'\n",
      " '34K' '.75K' '190K' '240K' '43K' '210K' '21K' '.3K' '590K' '164K' '1.1M'\n",
      " '.04M' '.01M' '.15K' '.85K' '294K' '632K' '245K' '146K' '1.37M' '1.59M'\n",
      " '932K' '237K' '975K' '887K' '113K' '1.34M' '1.14M' '1.32M' '109K' '177K'\n",
      " '996K' '552K' '100M' '7M' '14.4M' '11.5M' '18K' '25M' '60M' '20M' '17K'\n",
      " '1.04M' '35M' '.9K' '9.72M' '13M' '2.75M' '480K' '11M' '225K' '7.5K'\n",
      " '69M' '550K' '290K' '64K' '76K' '5.99M' '515K' '.8K' '1.25K' '12M'\n",
      " '4.44M' '2.38M' '5.55M' '4.36M' '3.17M' '1.99M' '6.34M' '3.9M' '180K'\n",
      " '775K' '70M' '118K' '28K' '.05M' '580K' '1.2K' '5.7M' '24K' '9.5M'\n",
      " '411.14K' '1.3M' '280.1K' '.4K' '275K' '98K' '1.25M' '1.8M' '17.5K'\n",
      " '470K' '.7K' '3.1K' '531.1K' 'K']\n",
      "1\n",
      "['1B' '32.5M' '3M' '0' '750K' '10K' '1.3M' '0K' '1M' '30K' '50K' '3K'\n",
      " '15K' '500K' '300M' '2K' '5K' '3.9M' '1.52M' '4.02M' '2.5M' '1K' '112.5K'\n",
      " '200M' '250K' '100K' '18.2M' '27.2M' '20M' '200K' '400K' '16.6M' '16M'\n",
      " '2.2M' '1.96M' '9.1M' '5.8M' '20K' '300K' '2M' '90M' '5M' '100M' '40K'\n",
      " '125K' '700K' '180K' '75K' '.1K' '.2K' '25K']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the unique columns and the one anomaly\n",
    "print(df[df['DAMAGE_PROPERTY'].notna()]['DAMAGE_PROPERTY'].unique())\n",
    "print(sum(df[df['DAMAGE_PROPERTY'].notna()]['DAMAGE_PROPERTY']=='K'))\n",
    "\n",
    "print(df[df['DAMAGE_CROPS'].notna()]['DAMAGE_CROPS'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the original DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1B\n",
      "32.5M\n",
      "3M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "750K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "10K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1.3M\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "10K\n",
      "10K\n",
      "0\n",
      "0\n",
      "30K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "50K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "15K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "500K\n",
      "300M\n",
      "0\n",
      "10K\n",
      "2K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "30K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3.9M\n",
      "1.52M\n",
      "4.02M\n",
      "2.5M\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "1K\n",
      "112.5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "200M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "500K\n",
      "0\n",
      "0\n",
      "0\n",
      "250K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "100K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "18.2M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "27.2M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "50K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "15K\n",
      "15K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "50K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "250K\n",
      "750K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "20M\n",
      "0\n",
      "0\n",
      "0\n",
      "50K\n",
      "200K\n",
      "400K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "16.6M\n",
      "16M\n",
      "2.2M\n",
      "0K\n",
      "1.96M\n",
      "9.1M\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "5.8M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "20K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "200K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "300K\n",
      "500K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "2M\n",
      "0K\n",
      "0\n",
      "300K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "200K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "200K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "1M\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "1M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "500K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "200K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "5K\n",
      "0\n",
      "90M\n",
      "300K\n",
      "2M\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "5K\n",
      "0\n",
      "5K\n",
      "5K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2K\n",
      "100K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "100M\n",
      "0\n",
      "500K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "3K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "40K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2K\n",
      "2K\n",
      "0\n",
      "2K\n",
      "3K\n",
      "3K\n",
      "5K\n",
      "0\n",
      "0\n",
      "125K\n",
      "200K\n",
      "5K\n",
      "300K\n",
      "2K\n",
      "2K\n",
      "2K\n",
      "0\n",
      "250K\n",
      "2K\n",
      "3K\n",
      "5K\n",
      "5K\n",
      "2K\n",
      "5K\n",
      "5K\n",
      "2K\n",
      "2K\n",
      "2K\n",
      "2K\n",
      "5K\n",
      "2K\n",
      "2K\n",
      "2K\n",
      "2K\n",
      "5K\n",
      "2K\n",
      "5K\n",
      "2K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "20K\n",
      "0\n",
      "0\n",
      "200K\n",
      "0\n",
      "0\n",
      "1M\n",
      "200K\n",
      "1M\n",
      "300K\n",
      "100K\n",
      "2K\n",
      "300K\n",
      "200K\n",
      "400K\n",
      "700K\n",
      "500K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "200K\n",
      "700K\n",
      "0K\n",
      "100K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0\n",
      "10K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "3K\n",
      "180K\n",
      "5K\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "1M\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "75K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      ".1K\n",
      "1K\n",
      ".2K\n",
      "0\n",
      "0\n",
      "1K\n",
      "1K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2K\n",
      "2K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "5K\n",
      "0\n",
      "25K\n",
      "0\n",
      "1K\n",
      "1K\n",
      "2K\n",
      "1K\n",
      "1K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "10K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1K\n",
      "5K\n",
      "2K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1K\n",
      "1K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "5K\n",
      "5K\n",
      "5K\n",
      "0\n",
      "5K\n",
      "0\n",
      "0\n",
      "5K\n",
      "5K\n",
      "5K\n",
      "0\n",
      "0\n",
      "25K\n",
      "0\n",
      "0\n",
      "5K\n",
      "5K\n",
      "5K\n",
      "0\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "250K\n",
      "100K\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "0K\n",
      "200K\n",
      "0K\n",
      "5K\n"
     ]
    }
   ],
   "source": [
    "# Clean Up the damage property/crops data\n",
    "df['DAMAGE_PROPERTY'] = df[df['DAMAGE_PROPERTY'] == 'K']['DAMAGE_PROPERTY'] = 1000  # Reporting error\n",
    "\n",
    "# Get the string abbr. out\n",
    "df['DAMAGE_CROPS'] = df['DAMAGE_CROPS'].replace(\"\", float('nan')).apply(convert_abbreviated_string)\n",
    "df['DAMAGE_PROPERTY'] = df['DAMAGE_PROPERTY'].replace(\"\", float('nan')).apply(convert_abbreviated_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create The DB Schema on exasol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExaQueryError",
     "evalue": "\n(\n    message     =>  object WEATHER_EVENTS already exists (Session: 1816733996904888337)\n    dsn         =>  192.168.56.101/E2B01857E4275EFD71F318801EA24D42A90C9EE2EE8F6A9899662520465CF79D:8563\n    user        =>  sys\n    schema      =>  \n    session_id  =>  1816733996904888337\n    code        =>  42500\n    query       =>  CREATE TABLE AOL_SCHEMA.WEATHER_EVENTS (\n    BEGIN_DATE_TIME TIMESTAMP,\n    END_DATE_TIME TIMESTAMP,\n    EVENT_TYPE VARCHAR(100),\n    BEGIN_DAY INTEGER,\n    END_DAY INTEGER,\n    STATE_FIPS INTEGER,\n    INJURIES_DIRECT INTEGER,\n    INJURIES_INDIRECT INTEGER,\n    DEATHS_DIRECT INTEGER,\n    DEATHS_INDIRECT INTEGER,\n    DAMAGE_PROPERTY INTEGER,\n    DAMAGE_CROPS FLOAT,\n    EPISODE_ID INT,\n    EVENT_ID INT NOT NULL,\n    BEGIN_MONTH INTEGER,\n    END_MONTH INTEGER,\n    REGION VARCHAR(100),\n    PRIMARY KEY (EVENT_ID)\n)\n)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExaQueryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m\n\u001b[0;32m      1\u001b[0m create_table_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mCREATE TABLE AOL_SCHEMA.WEATHER_EVENTS (\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    BEGIN_DATE_TIME TIMESTAMP,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m)\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# conn.execute(\"DROP TABLE AOL_SCHEMA.WEATHER_EVENTS\")\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_table_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anwender\\VSProjects\\BHT_BI_WiSe2425\\venv\\Lib\\site-packages\\pyexasol\\connection.py:208\u001b[0m, in \u001b[0;36mExaConnection.execute\u001b[1;34m(self, query, query_params)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExaStatement:\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    Execute SQL query with optional query formatting parameters\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    Return ExaStatement object\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anwender\\VSProjects\\BHT_BI_WiSe2425\\venv\\Lib\\site-packages\\pyexasol\\statement.py:55\u001b[0m, in \u001b[0;36mExaStatement.__init__\u001b[1;34m(self, connection, query, query_params, prepare, meta_nosql, **options)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_meta_nosql()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anwender\\VSProjects\\BHT_BI_WiSe2425\\venv\\Lib\\site-packages\\pyexasol\\statement.py:157\u001b[0m, in \u001b[0;36mExaStatement._execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 157\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msqlText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39mws_req_time\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_result_set(ret)\n",
      "File \u001b[1;32mc:\\Users\\Anwender\\VSProjects\\BHT_BI_WiSe2425\\venv\\Lib\\site-packages\\pyexasol\\connection.py:572\u001b[0m, in \u001b[0;36mExaConnection.req\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    570\u001b[0m         cls_err \u001b[38;5;241m=\u001b[39m ExaQueryError\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m cls_err(\u001b[38;5;28mself\u001b[39m, req[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlText\u001b[39m\u001b[38;5;124m'\u001b[39m], ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlCode\u001b[39m\u001b[38;5;124m'\u001b[39m], ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m req\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExaAuthError(\u001b[38;5;28mself\u001b[39m, ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlCode\u001b[39m\u001b[38;5;124m'\u001b[39m], ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mExaQueryError\u001b[0m: \n(\n    message     =>  object WEATHER_EVENTS already exists (Session: 1816733996904888337)\n    dsn         =>  192.168.56.101/E2B01857E4275EFD71F318801EA24D42A90C9EE2EE8F6A9899662520465CF79D:8563\n    user        =>  sys\n    schema      =>  \n    session_id  =>  1816733996904888337\n    code        =>  42500\n    query       =>  CREATE TABLE AOL_SCHEMA.WEATHER_EVENTS (\n    BEGIN_DATE_TIME TIMESTAMP,\n    END_DATE_TIME TIMESTAMP,\n    EVENT_TYPE VARCHAR(100),\n    BEGIN_DAY INTEGER,\n    END_DAY INTEGER,\n    STATE_FIPS INTEGER,\n    INJURIES_DIRECT INTEGER,\n    INJURIES_INDIRECT INTEGER,\n    DEATHS_DIRECT INTEGER,\n    DEATHS_INDIRECT INTEGER,\n    DAMAGE_PROPERTY INTEGER,\n    DAMAGE_CROPS FLOAT,\n    EPISODE_ID INT,\n    EVENT_ID INT NOT NULL,\n    BEGIN_MONTH INTEGER,\n    END_MONTH INTEGER,\n    REGION VARCHAR(100),\n    PRIMARY KEY (EVENT_ID)\n)\n)\n"
     ]
    }
   ],
   "source": [
    "create_table_query = '''\n",
    "CREATE TABLE AOL_SCHEMA.WEATHER_EVENTS (\n",
    "    BEGIN_DATE_TIME TIMESTAMP,\n",
    "    END_DATE_TIME TIMESTAMP,\n",
    "    EVENT_TYPE VARCHAR(100),\n",
    "    BEGIN_DAY INTEGER,\n",
    "    END_DAY INTEGER,\n",
    "    STATE_FIPS INTEGER,\n",
    "    INJURIES_DIRECT INTEGER,\n",
    "    INJURIES_INDIRECT INTEGER,\n",
    "    DEATHS_DIRECT INTEGER,\n",
    "    DEATHS_INDIRECT INTEGER,\n",
    "    DAMAGE_PROPERTY INTEGER,\n",
    "    DAMAGE_CROPS FLOAT,\n",
    "    EPISODE_ID INT,\n",
    "    EVENT_ID INT NOT NULL,\n",
    "    BEGIN_MONTH INTEGER,\n",
    "    END_MONTH INTEGER,\n",
    "    REGION VARCHAR(100),\n",
    "    PRIMARY KEY (EVENT_ID)\n",
    ")\n",
    "'''\n",
    "# conn.execute(\"DROP TABLE AOL_SCHEMA.WEATHER_EVENTS\")\n",
    "conn.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BEGIN_DATE_TIME', 'TIMESTAMP', 'TRUE', 'FALSE')\n",
      "('END_DATE_TIME', 'TIMESTAMP', 'TRUE', 'FALSE')\n",
      "('EVENT_TYPE', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('BEGIN_DAY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('END_DAY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('STATE_FIPS', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('INJURIES_DIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('INJURIES_INDIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DEATHS_DIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DEATHS_INDIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DAMAGE_PROPERTY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DAMAGE_CROPS', 'DOUBLE', 'TRUE', 'FALSE')\n",
      "('EPISODE_ID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('EVENT_ID', 'DECIMAL(18,0)', 'FALSE', 'FALSE')\n",
      "('BEGIN_MONTH', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('END_MONTH', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('REGION', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n"
     ]
    }
   ],
   "source": [
    "query = \"DESCRIBE AOL_SCHEMA.WEATHER_EVENTS\"  # Replace with your schema and table name\n",
    "result = conn.execute(query)\n",
    "\n",
    "# Fetch and print the results\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_DATE_TIME', 'END_DATE_TIME', 'EVENT_TYPE', 'BEGIN_DAY',\n",
       "       'END_DAY', 'STATE_FIPS', 'INJURIES_DIRECT', 'INJURIES_INDIRECT',\n",
       "       'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS',\n",
       "       'EPISODE_ID', 'EVENT_ID', 'BEGIN_MONTH', 'END_MONTH', 'REGION'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BEGIN_DATE_TIME       END_DATE_TIME                EVENT_TYPE  \\\n",
      "0     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "1     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "2     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "3     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "4     2006-01-01 00:00:00 2006-01-31 23:59:00                   Drought   \n",
      "...                   ...                 ...                       ...   \n",
      "25728 2006-05-31 21:10:00 2006-05-31 22:10:00  Marine Thunderstorm Wind   \n",
      "25729 2006-05-31 21:10:00 2006-05-31 22:15:00  Marine Thunderstorm Wind   \n",
      "25730 2006-05-31 22:00:00 2006-05-31 22:00:00         Thunderstorm Wind   \n",
      "25731 2006-05-31 22:05:00 2006-05-31 22:05:00         Thunderstorm Wind   \n",
      "25732 2006-05-31 23:05:00 2006-05-31 23:05:00         Thunderstorm Wind   \n",
      "\n",
      "       BEGIN_DAY  END_DAY  STATE_FIPS  INJURIES_DIRECT  INJURIES_INDIRECT  \\\n",
      "0              1       31           8                0                  0   \n",
      "1              1       31          48                0                  0   \n",
      "2              1       31          48                0                  0   \n",
      "3              1       31          40                0                  0   \n",
      "4              1       31          40                0                  0   \n",
      "...          ...      ...         ...              ...                ...   \n",
      "25728         31       31          95                0                  0   \n",
      "25729         31       31          95                0                  0   \n",
      "25730         31       31          36                0                  0   \n",
      "25731         31       31          39                0                  0   \n",
      "25732         31       31          54                0                  0   \n",
      "\n",
      "       DEATHS_DIRECT  DEATHS_INDIRECT  DAMAGE_PROPERTY  DAMAGE_CROPS  \\\n",
      "0                  0                0             1000           NaN   \n",
      "1                  0                0             1000           NaN   \n",
      "2                  0                0             1000           NaN   \n",
      "3                  0                0             1000           NaN   \n",
      "4                  0                0             1000           NaN   \n",
      "...              ...              ...              ...           ...   \n",
      "25728              0                0             1000           NaN   \n",
      "25729              0                0             1000           NaN   \n",
      "25730              0                0             1000           NaN   \n",
      "25731              0                0             1000           NaN   \n",
      "25732              0                0             1000           NaN   \n",
      "\n",
      "       EPISODE_ID  EVENT_ID  BEGIN_MONTH  END_MONTH         REGION  \n",
      "0          202408   5482479            1          1       Colorado  \n",
      "1          203632   5486559            1          1          Texas  \n",
      "2          203632   5486558            1          1          Texas  \n",
      "3          203694   5486086            1          1       Oklahoma  \n",
      "4          203694   5486085            1          1       Oklahoma  \n",
      "...           ...       ...          ...        ...            ...  \n",
      "25728      211946   5512621            5          5      Lake erie  \n",
      "25729      211946   5512620            5          5      Lake erie  \n",
      "25730      209876   5505143            5          5       New york  \n",
      "25731      211942   5512434            5          5           Ohio  \n",
      "25732      206999   5497477            5          5  West virginia  \n",
      "\n",
      "[19194 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicates based on a specific column (e.g., 'EVENT_ID')\n",
    "duplicates_df = df[df.duplicated(subset='EPISODE_ID', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(duplicates_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_DATE_TIME</th>\n",
       "      <th>END_DATE_TIME</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>INJURIES_INDIRECT</th>\n",
       "      <th>DEATHS_DIRECT</th>\n",
       "      <th>DEATHS_INDIRECT</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>BEGIN_MONTH</th>\n",
       "      <th>END_MONTH</th>\n",
       "      <th>REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482473</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482472</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482471</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482470</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482467</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482468</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482478</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482476</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482475</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482466</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482465</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-31 23:59:00</td>\n",
       "      <td>Drought</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>5482463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BEGIN_DATE_TIME       END_DATE_TIME EVENT_TYPE  BEGIN_DAY  END_DAY  \\\n",
       "0        2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "201      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "202      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "203      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "204      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "291      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "292      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "293      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "295      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "312      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "313      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "314      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "315      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "316      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "317      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "318      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "319      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "320      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "321      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "322      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "323      2006-01-01 2006-01-31 23:59:00    Drought          1       31   \n",
       "\n",
       "     STATE_FIPS  INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  \\\n",
       "0             8                0                  0              0   \n",
       "201           8                0                  0              0   \n",
       "202           8                0                  0              0   \n",
       "203           8                0                  0              0   \n",
       "204           8                0                  0              0   \n",
       "291           8                0                  0              0   \n",
       "292           8                0                  0              0   \n",
       "293           8                0                  0              0   \n",
       "295           8                0                  0              0   \n",
       "312           8                0                  0              0   \n",
       "313           8                0                  0              0   \n",
       "314           8                0                  0              0   \n",
       "315           8                0                  0              0   \n",
       "316           8                0                  0              0   \n",
       "317           8                0                  0              0   \n",
       "318           8                0                  0              0   \n",
       "319           8                0                  0              0   \n",
       "320           8                0                  0              0   \n",
       "321           8                0                  0              0   \n",
       "322           8                0                  0              0   \n",
       "323           8                0                  0              0   \n",
       "\n",
       "     DEATHS_INDIRECT  DAMAGE_PROPERTY  DAMAGE_CROPS  EPISODE_ID  EVENT_ID  \\\n",
       "0                  0             1000           NaN      202408   5482479   \n",
       "201                0             1000           NaN      202408   5482474   \n",
       "202                0             1000           NaN      202408   5482473   \n",
       "203                0             1000           NaN      202408   5482472   \n",
       "204                0             1000           NaN      202408   5482471   \n",
       "291                0             1000           NaN      202408   5482470   \n",
       "292                0             1000           NaN      202408   5482469   \n",
       "293                0             1000           NaN      202408   5482467   \n",
       "295                0             1000           NaN      202408   5482468   \n",
       "312                0             1000           NaN      202408   5482478   \n",
       "313                0             1000           NaN      202408   5482477   \n",
       "314                0             1000           NaN      202408   5482476   \n",
       "315                0             1000           NaN      202408   5482475   \n",
       "316                0             1000           NaN      202408   5482462   \n",
       "317                0             1000           NaN      202408   5482461   \n",
       "318                0             1000           NaN      202408   5482460   \n",
       "319                0             1000           NaN      202408   5482459   \n",
       "320                0             1000           NaN      202408   5482466   \n",
       "321                0             1000           NaN      202408   5482465   \n",
       "322                0             1000           NaN      202408   5482464   \n",
       "323                0             1000           NaN      202408   5482463   \n",
       "\n",
       "     BEGIN_MONTH  END_MONTH    REGION  \n",
       "0              1          1  Colorado  \n",
       "201            1          1  Colorado  \n",
       "202            1          1  Colorado  \n",
       "203            1          1  Colorado  \n",
       "204            1          1  Colorado  \n",
       "291            1          1  Colorado  \n",
       "292            1          1  Colorado  \n",
       "293            1          1  Colorado  \n",
       "295            1          1  Colorado  \n",
       "312            1          1  Colorado  \n",
       "313            1          1  Colorado  \n",
       "314            1          1  Colorado  \n",
       "315            1          1  Colorado  \n",
       "316            1          1  Colorado  \n",
       "317            1          1  Colorado  \n",
       "318            1          1  Colorado  \n",
       "319            1          1  Colorado  \n",
       "320            1          1  Colorado  \n",
       "321            1          1  Colorado  \n",
       "322            1          1  Colorado  \n",
       "323            1          1  Colorado  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['EPISODE_ID']==202408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25734, 17)\n",
      "(19882, 17)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace NaN values with None\n",
    "df = df.where(pd.notnull(df), None)\n",
    "print(df.shape)\n",
    "\n",
    "# Remove duplicates based on all columns except 'EVENT_ID'\n",
    "columns_except_event_id = df.columns[df.columns != 'EVENT_ID']\n",
    "\n",
    "# Drop duplicates based on all columns except 'EVENT_ID'\n",
    "distinct_df = df.drop_duplicates(subset=columns_except_event_id)\n",
    "\n",
    "# Check the result\n",
    "print(distinct_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.import_from_pandas(distinct_df, table=('AOL_SCHEMA', 'WEATHER_EVENTS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BEGIN_DATE_TIME', 'TIMESTAMP', 'TRUE', 'FALSE')\n",
      "('END_DATE_TIME', 'TIMESTAMP', 'TRUE', 'FALSE')\n",
      "('EVENT_TYPE', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('BEGIN_DAY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('END_DAY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('STATE_FIPS', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('INJURIES_DIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('INJURIES_INDIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DEATHS_DIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DEATHS_INDIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DAMAGE_PROPERTY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DAMAGE_CROPS', 'DOUBLE', 'TRUE', 'FALSE')\n",
      "('EPISODE_ID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('EVENT_ID', 'DECIMAL(18,0)', 'FALSE', 'FALSE')\n",
      "('BEGIN_MONTH', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('END_MONTH', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('REGION', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n"
     ]
    }
   ],
   "source": [
    "query = \"DESCRIBE AOL_SCHEMA.WEATHER_EVENTS\"  # Replace with your schema and table name\n",
    "result = conn.execute(query)\n",
    "\n",
    "# Fetch and print the results\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2006-01-01 00:00:00.000000', 'Drought', 'Colorado', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'Drought', 'Texas', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'Drought', 'Oklahoma', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'WINTER WEATHER', 'Colorado', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'WINTER WEATHER', 'Utah', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'Drought', 'Texas', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'Drought', 'Texas', 0, 0, 0, 0, 1000, 1000000000)\n",
      "('2006-01-01 00:00:00.000000', 'Drought', 'Oklahoma', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'Drought', 'Arkansas', 0, 0, 0, 0, 1000, None)\n",
      "('2006-01-01 00:00:00.000000', 'Heat', 'New york', 0, 0, 0, 0, 1000, None)\n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    BEGIN_DATE_TIME, \n",
    "    EVENT_TYPE, \n",
    "    REGION, \n",
    "    INJURIES_DIRECT, \n",
    "    INJURIES_INDIRECT, \n",
    "    DEATHS_DIRECT, \n",
    "    DEATHS_INDIRECT, \n",
    "    DAMAGE_PROPERTY, \n",
    "    DAMAGE_CROPS\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "result = conn.execute(query)\n",
    "\n",
    "# Fetch and print the results\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('QUERYID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('TIMEID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('ANONID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('URLID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('IRANK', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('CLICK', 'BOOLEAN', 'TRUE', 'FALSE')\n"
     ]
    }
   ],
   "source": [
    "# Query to describe the FACTS table\n",
    "describe_query = \"DESCRIBE AOL_SCHEMA.FACTS\"\n",
    "\n",
    "# Execute and print the results\n",
    "result = conn.execute(describe_query)\n",
    "for row in result:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describing table: AOL_SCHEMA.FACTS\n",
      "('QUERYID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('TIMEID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('ANONID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('URLID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('IRANK', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('CLICK', 'BOOLEAN', 'TRUE', 'FALSE')\n",
      "\n",
      "\n",
      "Describing table: AOL_SCHEMA.URLDIM\n",
      "('URL', 'VARCHAR(5000) UTF8', 'TRUE', 'FALSE')\n",
      "('ID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('TITLE', 'VARCHAR(1000) UTF8', 'TRUE', 'FALSE')\n",
      "('DESCRIPTION', 'VARCHAR(2000000) UTF8', 'TRUE', 'FALSE')\n",
      "('PROTOCOL', 'VARCHAR(50) UTF8', 'TRUE', 'FALSE')\n",
      "('SUBDOMAIN', 'VARCHAR(1000) UTF8', 'TRUE', 'FALSE')\n",
      "('THISDOMAIN', 'VARCHAR(2500) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPLEVELDOMAIN', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('THISPATH', 'VARCHAR(2000) UTF8', 'TRUE', 'FALSE')\n",
      "\n",
      "\n",
      "Describing table: AOL_SCHEMA.DMOZ_CATEGORIES\n",
      "('CATID', 'DECIMAL(36,0)', 'TRUE', 'FALSE')\n",
      "('TOPIC', 'VARCHAR(512) UTF8', 'TRUE', 'FALSE')\n",
      "('TITLE', 'VARCHAR(256) UTF8', 'TRUE', 'FALSE')\n",
      "('DESCRIPTION', 'VARCHAR(2000000) UTF8', 'TRUE', 'FALSE')\n",
      "('LASTUPDATE', 'VARCHAR(20) UTF8', 'TRUE', 'FALSE')\n",
      "('LETTERBAR', 'VARCHAR(1) UTF8', 'TRUE', 'FALSE')\n",
      "('FATHERID', 'DECIMAL(36,0)', 'TRUE', 'FALSE')\n",
      "('TOPIC_1', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_2', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_3', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_4', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_5', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_6', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_7', 'VARCHAR(111) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_8', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_9', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_10', 'VARCHAR(103) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_11', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_12', 'VARCHAR(107) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_13', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_14', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('TOPIC_15', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "\n",
      "\n",
      "Describing table: AOL_SCHEMA.WEATHER_EVENTS\n",
      "('BEGIN_DATE_TIME', 'TIMESTAMP', 'TRUE', 'FALSE')\n",
      "('END_DATE_TIME', 'TIMESTAMP', 'TRUE', 'FALSE')\n",
      "('EVENT_TYPE', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "('BEGIN_DAY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('END_DAY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('STATE_FIPS', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('INJURIES_DIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('INJURIES_INDIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DEATHS_DIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DEATHS_INDIRECT', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DAMAGE_PROPERTY', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('DAMAGE_CROPS', 'DOUBLE', 'TRUE', 'FALSE')\n",
      "('EPISODE_ID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('EVENT_ID', 'DECIMAL(18,0)', 'FALSE', 'FALSE')\n",
      "('BEGIN_MONTH', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('END_MONTH', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n",
      "('REGION', 'VARCHAR(100) UTF8', 'TRUE', 'FALSE')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of tables to describe\n",
    "tables = [\"AOL_SCHEMA.FACTS\", \"AOL_SCHEMA.URLDIM\", \"AOL_SCHEMA.DMOZ_CATEGORIES\", \"AOL_SCHEMA.WEATHER_EVENTS\"]\n",
    "\n",
    "# Describe each table and print the results\n",
    "for table in tables:\n",
    "    print(f\"Describing table: {table}\")\n",
    "    describe_query = f\"DESCRIBE {table}\"\n",
    "    result = conn.execute(describe_query)\n",
    "    for row in result:\n",
    "        print(row)\n",
    "    print(\"\\n\")  # Add space between table descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOL_SCHEMA.FACTS: (36389566,)\n",
      "AOL_SCHEMA.URLDIM: (4051750,)\n",
      "AOL_SCHEMA.DMOZ_CATEGORIES: (779122,)\n",
      "AOL_SCHEMA.WEATHER_EVENTS: (19882,)\n"
     ]
    }
   ],
   "source": [
    "tables = [\"AOL_SCHEMA.FACTS\", \"AOL_SCHEMA.URLDIM\", \"AOL_SCHEMA.DMOZ_CATEGORIES\", \"AOL_SCHEMA.WEATHER_EVENTS\"]\n",
    "\n",
    "for table in tables:\n",
    "    query = f\"SELECT COUNT(*) AS row_count FROM {table}\"\n",
    "    result = conn.execute(query)\n",
    "    print(f\"{table}: {result.fetchone()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   URLID    ID THISDOMAIN\n",
      "0   3649  3649   thetrain\n",
      "1   3649  3649   thetrain\n",
      "2   3649  3649   thetrain\n",
      "3   3649  3649   thetrain\n",
      "4   3649  3649   thetrain\n",
      "5   3649  3649   thetrain\n",
      "6   3649  3649   thetrain\n",
      "7   3649  3649   thetrain\n",
      "8   3649  3649   thetrain\n",
      "9   3649  3649   thetrain\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT f.URLID, u.ID, u.THISDOMAIN\n",
    "FROM AOL_SCHEMA.FACTS f\n",
    "JOIN AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "result = conn.export_to_pandas(query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct THISDOMAIN values in URLDIM:\n",
      "            THISDOMAIN\n",
      "0        vibratormotor\n",
      "1     projectaware.org\n",
      "2         buchetcetera\n",
      "3             tdivadlo\n",
      "4        onlineclasses\n",
      "5           maresdream\n",
      "6     beautyonline.com\n",
      "7       mnnewspapernet\n",
      "8  thingsnigerianslove\n",
      "9              xpclean\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT THISDOMAIN\n",
    "FROM AOL_SCHEMA.URLDIM\n",
    "WHERE THISDOMAIN IS NOT NULL\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "result = conn.export_to_pandas(query)\n",
    "print(\"Distinct THISDOMAIN values in URLDIM:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct TOPIC values in DMOZ_CATEGORIES:\n",
      "                                               TOPIC\n",
      "0  Top/Sports/Skating/Ice_Skating/Events/National...\n",
      "1  Top/World/Greek/Κατά_Περιοχή/Ευρώπη/Ελλάδα/Νομ...\n",
      "2                  Top/Home/Family/Family_Websites/N\n",
      "3  Top/World/Russian/Страны_и_регионы/Европа/Росс...\n",
      "4  Top/Regional/Europe/United_Kingdom/England/Ess...\n",
      "5  Top/Recreation/Autos/Makes_and_Models/Nissan/2...\n",
      "6     Top/World/Svenska/Kultur/Scenkonst/Dans/Balett\n",
      "7        Top/World/Català/Arts/Música/Estils/Country\n",
      "8  Top/Regional/North_America/United_States/Utah/...\n",
      "9  Top/Recreation/Outdoors/Organizations/North_Am...\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT TOPIC\n",
    "FROM AOL_SCHEMA.DMOZ_CATEGORIES\n",
    "WHERE TOPIC IS NOT NULL\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "result = conn.export_to_pandas(query)\n",
    "print(\"Distinct TOPIC values in DMOZ_CATEGORIES:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [THISDOMAIN, TOPIC]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT u.THISDOMAIN, c.TOPIC\n",
    "FROM AOL_SCHEMA.URLDIM u\n",
    "JOIN AOL_SCHEMA.DMOZ_CATEGORIES c ON LOWER(u.THISDOMAIN) = LOWER(TRIM(c.TOPIC))\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "result = conn.export_to_pandas(query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    c.TOPIC AS FULL_TOPIC_PATH,\n",
    "    REGEXP_SUBSTR(c.TOPIC, '[^/]+$', 1, 1) AS EXTRACTED_TOPIC, -- Extract the last segment of the topic\n",
    "    CASE \n",
    "        WHEN LOWER(u.THISDOMAIN) = LOWER(REGEXP_SUBSTR(c.TOPIC, '[^/]+$', 1, 1)) THEN 'Exact Match'\n",
    "        WHEN LOWER(c.TOPIC) LIKE CONCAT('%', LOWER(u.THISDOMAIN), '%') THEN 'Partial Match'\n",
    "        ELSE 'No Match'\n",
    "    END AS MATCH_TYPE\n",
    "FROM AOL_SCHEMA.URLDIM u\n",
    "LEFT JOIN AOL_SCHEMA.DMOZ_CATEGORIES c \n",
    "ON LOWER(u.THISDOMAIN) = LOWER(REGEXP_SUBSTR(c.TOPIC, '[^/]+$', 1, 1))\n",
    "   OR LOWER(c.TOPIC) LIKE CONCAT('%', LOWER(u.THISDOMAIN), '%')\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "result = conn.export_to_pandas(query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Events Analysis:\n",
      "          EVENT_TYPE    REGION  TOTAL_PROPERTY_DAMAGE  TOTAL_FATALITIES\n",
      "0               Hail  Missouri                1051000                 0\n",
      "1               Hail     Texas                 968000                 0\n",
      "2               Hail    Kansas                 745000                 0\n",
      "3               Hail  Illinois                 611000                 0\n",
      "4               Hail  Oklahoma                 542000                 0\n",
      "..               ...       ...                    ...               ...\n",
      "694       Dust Storm     Texas                   1000                 0\n",
      "695      Flash Flood  Nebraska                   1000                 0\n",
      "696  Cold/Wind Chill     Maine                   1000                 0\n",
      "697     Funnel Cloud  Oklahoma                   1000                 0\n",
      "698   WINTER WEATHER  Oklahoma                   1000                 0\n",
      "\n",
      "[699 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "query_weather = \"\"\"\n",
    "SELECT \n",
    "    EVENT_TYPE,\n",
    "    REGION,\n",
    "    SUM(DAMAGE_PROPERTY) AS total_property_damage,\n",
    "    SUM(DEATHS_DIRECT + DEATHS_INDIRECT) AS total_fatalities\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS\n",
    "GROUP BY EVENT_TYPE, REGION\n",
    "ORDER BY total_property_damage DESC, total_fatalities DESC;\n",
    "\"\"\"\n",
    "df_weather = conn.export_to_pandas(query_weather)\n",
    "print(\"Weather Events Analysis:\")\n",
    "print(df_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Categories Analysis based on URLDIM:\n",
      "  DOMAIN_NAME               WEBSITE_TITLE  TOTAL_QUERIES\n",
      "0         NaN                         NaN       16947036\n",
      "1      google            கூகிள் ( Google)         366623\n",
      "2     myspace        MySpace: Rata Blanca         167070\n",
      "3       yahoo                      Yahoo!         161082\n",
      "4   wikipedia  Vladimir Lenin - Wikipedia         122539\n",
      "5      amazon                      Amazon         106119\n",
      "6        imdb     imdb.de: Knight and Day          98549\n",
      "7    mapquest                    MapQuest          96215\n",
      "8        ebay                        eBay          77962\n",
      "9       yahoo                 Yahoo! Mail          53856\n"
     ]
    }
   ],
   "source": [
    "query_facts = \"\"\"\n",
    "SELECT \n",
    "    u.THISDOMAIN AS domain_name,  -- Changed alias to domain_name\n",
    "    u.TITLE AS website_title,\n",
    "    COUNT(f.QUERYID) AS total_queries\n",
    "FROM AOL_SCHEMA.FACTS f\n",
    "JOIN AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "GROUP BY u.THISDOMAIN, u.TITLE\n",
    "ORDER BY total_queries DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_facts = conn.export_to_pandas(query_facts)\n",
    "print(\"Website Categories Analysis based on URLDIM:\")\n",
    "print(df_facts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "          DOMAIN_NAME                    WEBSITE_TITLE  TOTAL_QUERIES\n",
      "0             weather              The Weather Channel          13959\n",
      "1        wunderground              Weather underground           9824\n",
      "2            nws.noaa  National Weather Service (NNAA)           3372\n",
      "3         accuweather                      AccuWeather           2785\n",
      "4               yahoo          Yahoo! Weather - Brazil           2475\n",
      "5                noaa      NOAA NWS - Colombia Weather           1187\n",
      "6  weatherchannel.com              The Weather Channel           1075\n",
      "7            srh.noaa         National Weather Service            934\n",
      "8                noaa         NOAA Weather Information            754\n",
      "9        hamptonroads            Hampton Roads weather            628\n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT \n",
    "    u.THISDOMAIN AS domain_name,  -- Use domain_name as alias\n",
    "    u.TITLE AS website_title,\n",
    "    COUNT(f.QUERYID) AS total_queries\n",
    "FROM AOL_SCHEMA.FACTS f\n",
    "JOIN AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "WHERE LOWER(u.TITLE) LIKE '%weather%' OR LOWER(u.TITLE) LIKE '%emergency%' OR LOWER(u.TITLE) LIKE '%flood%'\n",
    "GROUP BY u.THISDOMAIN, u.TITLE\n",
    "ORDER BY total_queries DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "Empty DataFrame\n",
      "Columns: [EVENT_TYPE, REGION, DOMAIN_NAME, WEBSITE_TITLE, TOTAL_PROPERTY_DAMAGE, TOTAL_FATALITIES, TOTAL_QUERIES]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT\n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    u.TITLE AS WEBSITE_TITLE,\n",
    "    SUM(w.DAMAGE_PROPERTY) AS TOTAL_PROPERTY_DAMAGE,\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) AS TOTAL_FATALITIES,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES\n",
    "FROM\n",
    "    AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID -- Assuming URLID maps to STATE_FIPS\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "WHERE\n",
    "    LOWER(u.TITLE) LIKE '%weather%'\n",
    "    OR LOWER(u.TITLE) LIKE '%emergency%'\n",
    "    OR LOWER(u.TITLE) LIKE '%flood%'\n",
    "GROUP BY\n",
    "    w.EVENT_TYPE, w.REGION, u.THISDOMAIN, u.TITLE\n",
    "ORDER BY\n",
    "    TOTAL_PROPERTY_DAMAGE DESC,\n",
    "    TOTAL_FATALITIES DESC,\n",
    "    TOTAL_QUERIES DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "   DOMAIN_TOPIC_MATCH\n",
      "0                5854\n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT COUNT(*) AS DOMAIN_TOPIC_MATCH\n",
    "FROM AOL_SCHEMA.URLDIM u\n",
    "JOIN AOL_SCHEMA.DMOZ_CATEGORIES c \n",
    "ON u.THISDOMAIN = REGEXP_SUBSTR(c.TOPIC, '[^/]+$', 1, 1);\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "   STATE_FIPS\n",
      "0           1\n",
      "1           2\n",
      "2           4\n",
      "3           5\n",
      "4           6\n",
      "5           8\n",
      "6           9\n",
      "7          10\n",
      "8          11\n",
      "9          12\n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT DISTINCT STATE_FIPS\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "   URLID\n",
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "4      5\n",
      "5      6\n",
      "6      7\n",
      "7      8\n",
      "8      9\n",
      "9     10\n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT DISTINCT URLID\n",
    "FROM AOL_SCHEMA.FACTS\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "          EVENT_TYPE     REGION       DOMAIN_NAME         WEBSITE_TITLE  \\\n",
      "0               Hail     Kansas             crime                   NaN   \n",
      "1               Hail  Tennessee    buildingtrades                   NaN   \n",
      "2  Thunderstorm Wind  Tennessee    buildingtrades                   NaN   \n",
      "3               Hail   Illinois          mybrotha          Mybrotha.com   \n",
      "4          High Wind     Oregon        watsonrent                   NaN   \n",
      "5               Hail    Indiana  elliscountypress    Ellis County Press   \n",
      "6               Hail  Wisconsin    kingdomhearts3      Kingdom Hearts 3   \n",
      "7               Hail   Michigan       lvbeethoven  Ludwig van Beethoven   \n",
      "8  Thunderstorm Wind   Illinois          mybrotha          Mybrotha.com   \n",
      "9  Thunderstorm Wind     Kansas             crime                   NaN   \n",
      "\n",
      "   TOTAL_PROPERTY_DAMAGE  TOTAL_FATALITIES  TOTAL_QUERIES  \n",
      "0                8195000                 0           8195  \n",
      "1                4908000                 0           4908  \n",
      "2                4056000                 0           4056  \n",
      "3                3666000                 0           3666  \n",
      "4                2862000                27           2862  \n",
      "5                2285000                 0           2285  \n",
      "6                2160000                 0           2160  \n",
      "7                2079000                 0           2079  \n",
      "8                2046000                 0           2046  \n",
      "9                1947000                 0           1947  \n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT\n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    u.TITLE AS WEBSITE_TITLE,\n",
    "    SUM(w.DAMAGE_PROPERTY) AS TOTAL_PROPERTY_DAMAGE,\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) AS TOTAL_FATALITIES,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES\n",
    "FROM\n",
    "    AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "GROUP BY w.EVENT_TYPE, w.REGION, u.THISDOMAIN, u.TITLE\n",
    "ORDER BY TOTAL_PROPERTY_DAMAGE DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "       EVENT_TYPE          REGION       DOMAIN_NAME   WEBSITE_TITLE  \\\n",
      "0  Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "1  Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "2  Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "3  Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "4    Winter Storm         Alabama  darrellmansfield             NaN   \n",
      "5    Winter Storm         Alabama  darrellmansfield             NaN   \n",
      "6    Winter Storm         Alabama  darrellmansfield             NaN   \n",
      "7    Winter Storm         Alabama  darrellmansfield             NaN   \n",
      "8      Waterspout       E pacific        rentclicks             NaN   \n",
      "9      Waterspout       E pacific        rentclicks             NaN   \n",
      "\n",
      "                        SEARCH_QUERY  CATEGORY_TOPIC  \n",
      "0          email bosanska kostajnica             NaN  \n",
      "1          email bosanska kostajnica             NaN  \n",
      "2          email bosanska kostajnica             NaN  \n",
      "3          email bosanska kostajnica             NaN  \n",
      "4                   darrel mansfield             NaN  \n",
      "5                   darrel mansfield             NaN  \n",
      "6                   darrel mansfield             NaN  \n",
      "7                   darrel mansfield             NaN  \n",
      "8  apartments in pine bluff arkansas             NaN  \n",
      "9     pine bluff arkansas apartments             NaN  \n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT\n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    u.TITLE AS WEBSITE_TITLE,\n",
    "    q.QUERY AS SEARCH_QUERY,\n",
    "    c.TOPIC AS CATEGORY_TOPIC\n",
    "FROM\n",
    "    AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.QUERYDIM q ON f.QUERYID = q.ID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.DMOZ_CATEGORIES c ON u.THISDOMAIN = REGEXP_SUBSTR(c.TOPIC, '[^/]+$', 1, 1)\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Analysis with Event Keywords:\n",
      "           EVENT_TYPE          REGION       DOMAIN_NAME   WEBSITE_TITLE  \\\n",
      "0      Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "1      Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "2      Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "3      Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "4        Winter Storm         Alabama  darrellmansfield             NaN   \n",
      "...               ...             ...               ...             ...   \n",
      "82628      Heavy Snow      Washington       safeshopper             NaN   \n",
      "82629      Heavy Snow      Washington       safeshopper             NaN   \n",
      "82630      Heavy Snow      Washington       safeshopper             NaN   \n",
      "82631      Heavy Snow      Washington       safeshopper             NaN   \n",
      "82632      Heavy Snow      Washington       safeshopper             NaN   \n",
      "\n",
      "                    SEARCH_QUERY  CATEGORY_TOPIC  \n",
      "0      email bosanska kostajnica             NaN  \n",
      "1      email bosanska kostajnica             NaN  \n",
      "2      email bosanska kostajnica             NaN  \n",
      "3      email bosanska kostajnica             NaN  \n",
      "4               darrel mansfield             NaN  \n",
      "...                          ...             ...  \n",
      "82628      barbara cosgrove lamp             NaN  \n",
      "82629           barbara cosgrove             NaN  \n",
      "82630         fusion table lamps             NaN  \n",
      "82631      barbara cosgrove lamp             NaN  \n",
      "82632      barbara cosgrove lamp             NaN  \n",
      "\n",
      "[82633 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "query_facts_keywords = \"\"\"\n",
    "SELECT\n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    u.TITLE AS WEBSITE_TITLE,\n",
    "    q.QUERY AS SEARCH_QUERY,\n",
    "    c.TOPIC AS CATEGORY_TOPIC\n",
    "FROM\n",
    "    AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.QUERYDIM q ON f.QUERYID = q.ID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.DMOZ_CATEGORIES c ON u.THISDOMAIN = c.TOPIC;\n",
    "\"\"\"\n",
    "df_facts_keywords = conn.export_to_pandas(query_facts_keywords)\n",
    "print(\"Website Analysis with Event Keywords:\")\n",
    "print(df_facts_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after removing duplicates:\n",
      "           EVENT_TYPE          REGION       DOMAIN_NAME   WEBSITE_TITLE  \\\n",
      "0      Winter Weather  North carolina        kostajnica  Kostajnica.com   \n",
      "4        Winter Storm         Alabama  darrellmansfield             NaN   \n",
      "8          Waterspout       E pacific        rentclicks             NaN   \n",
      "9          Waterspout       E pacific        rentclicks             NaN   \n",
      "10     Winter Weather        Virginia             sunoa             NaN   \n",
      "...               ...             ...               ...             ...   \n",
      "82576     Strong Wind          Kansas             crime             NaN   \n",
      "82578     Strong Wind          Kansas             crime             NaN   \n",
      "82580     Strong Wind          Kansas             crime             NaN   \n",
      "82581     Strong Wind          Kansas             crime             NaN   \n",
      "82582     Strong Wind          Kansas             crime             NaN   \n",
      "\n",
      "                            SEARCH_QUERY  CATEGORY_TOPIC  \n",
      "0              email bosanska kostajnica             NaN  \n",
      "4                       darrel mansfield             NaN  \n",
      "8      apartments in pine bluff arkansas             NaN  \n",
      "9         pine bluff arkansas apartments             NaN  \n",
      "10               free 20greeting 20cards             NaN  \n",
      "...                                  ...             ...  \n",
      "82576                      www.crime.org             NaN  \n",
      "82578                        crime rates             NaN  \n",
      "82580                        crime stats             NaN  \n",
      "82581                  poverty and crime             NaN  \n",
      "82582                              crime             NaN  \n",
      "\n",
      "[2520 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df_cleaned = df_facts_keywords.drop_duplicates()\n",
    "print(\"Data after removing duplicates:\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anwender\\AppData\\Local\\Temp\\ipykernel_20808\\2860728013.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['ALL_TEXT'] = df_cleaned['SEARCH_QUERY'].fillna('') + ' ' + df_cleaned['DOMAIN_NAME'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Combine SEARCH_QUERY and DOMAIN_NAME columns into one\n",
    "df_cleaned['ALL_TEXT'] = df_cleaned['SEARCH_QUERY'].fillna('') + ' ' + df_cleaned['DOMAIN_NAME'].fillna('')\n",
    "\n",
    "# Tokenize words (split by whitespace)\n",
    "all_words = ' '.join(df_cleaned['ALL_TEXT']).lower().split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Word  Frequency\n",
      "171        lvbeethoven        378\n",
      "95          watsonrent        272\n",
      "411              crime        234\n",
      "284      childalert.co        210\n",
      "66      kingdomhearts3        160\n",
      "168          beethoven        144\n",
      "141           mybrotha        120\n",
      "227  bentleypublishers        108\n",
      "258       bookooenergy         84\n",
      "142              black         82\n",
      "431     buildingtrades         81\n",
      "67             kingdom         80\n",
      "96              watson         80\n",
      "394   elliscountypress         80\n",
      "143                men         80\n",
      "100            florida         64\n",
      "92            property         64\n",
      "114             realty         64\n",
      "64              hearts         64\n",
      "38            magelang         60\n"
     ]
    }
   ],
   "source": [
    "# Count word frequencies\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "word_count_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency'])\n",
    "\n",
    "# Sort by frequency\n",
    "word_count_df = word_count_df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# print(word_count_df.head(20))  # Show the top 20 words\n",
    "# Define a list of stop words\n",
    "stop_words = {'the', 'and', 'of', 'to', 'a', 'in', 'for', 'is', 'on', 'with', 'at', 'by', 'from', 'an', '-', '3'}\n",
    "\n",
    "# Filter out stop words\n",
    "word_count_df = word_count_df[~word_count_df['Word'].isin(stop_words)]\n",
    "\n",
    "print(word_count_df.head(20))  # Show the top 20 meaningful words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Volume by Region:\n",
      "      REGION  TOTAL_QUERIES\n",
      "0     Kansas          11946\n",
      "1  Tennessee          10092\n",
      "2   Michigan           7803\n",
      "3   Illinois           7266\n",
      "4     Oregon           5751\n",
      "5    Indiana           4150\n",
      "6  Wisconsin           3705\n",
      "7   Kentucky           3308\n",
      "8    Alabama           2604\n",
      "9   Arkansas           1944\n"
     ]
    }
   ],
   "source": [
    "query_region = \"\"\"\n",
    "SELECT \n",
    "    w.REGION,\n",
    "    COUNT(f.QUERYID) AS total_queries\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID  -- Ensure STATE_FIPS and URLID match logically\n",
    "GROUP BY w.REGION\n",
    "ORDER BY total_queries DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df_region = conn.export_to_pandas(query_region)\n",
    "print(\"Query Volume by Region:\")\n",
    "print(df_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [THISDOMAIN, TOPIC]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT u.THISDOMAIN, c.TOPIC\n",
    "FROM AOL_SCHEMA.URLDIM u\n",
    "LEFT JOIN AOL_SCHEMA.DMOZ_CATEGORIES c\n",
    "ON u.THISDOMAIN = c.TOPIC\n",
    "WHERE c.TOPIC IS NOT NULL\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            EVENT_TYPE   REGION WEBSITE_CATEGORY  TOTAL_PROPERTY_DAMAGE  \\\n",
      "0                  NaN      NaN    Uncategorized               82633000   \n",
      "1                 Hail      NaN    Uncategorized               37350000   \n",
      "2    Thunderstorm Wind      NaN    Uncategorized               18939000   \n",
      "3                 Hail   Kansas    Uncategorized                8195000   \n",
      "4                 Hail   Kansas    Uncategorized                8195000   \n",
      "..                 ...      ...              ...                    ...   \n",
      "266          Avalanche  Montana    Uncategorized                   4000   \n",
      "267        Strong Wind  Arizona    Uncategorized                   4000   \n",
      "268          Avalanche  Montana    Uncategorized                   4000   \n",
      "269       Winter Storm  Arizona    Uncategorized                   4000   \n",
      "270       Winter Storm  Arizona    Uncategorized                   4000   \n",
      "\n",
      "     TOTAL_FATALITIES  TOTAL_QUERIES  GROUPING_EVENT_TYPE  GROUPING_REGION  \\\n",
      "0                 837          82633                    1                1   \n",
      "1                   0          37350                    0                1   \n",
      "2                   7          18939                    0                1   \n",
      "3                   0           8195                    0                0   \n",
      "4                   0           8195                    0                0   \n",
      "..                ...            ...                  ...              ...   \n",
      "266                 8              4                    0                0   \n",
      "267                 8              4                    0                0   \n",
      "268                 8              4                    0                0   \n",
      "269                 6              4                    0                0   \n",
      "270                 6              4                    0                0   \n",
      "\n",
      "     GROUPING_WEBSITE_CATEGORY  \n",
      "0                            1  \n",
      "1                            1  \n",
      "2                            1  \n",
      "3                            0  \n",
      "4                            1  \n",
      "..                         ...  \n",
      "266                          0  \n",
      "267                          1  \n",
      "268                          1  \n",
      "269                          0  \n",
      "270                          1  \n",
      "\n",
      "[271 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    CASE \n",
    "        WHEN c.TITLE IS NULL THEN 'Uncategorized'\n",
    "        ELSE c.TITLE\n",
    "    END AS WEBSITE_CATEGORY,\n",
    "    SUM(w.DAMAGE_PROPERTY) AS TOTAL_PROPERTY_DAMAGE,\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) AS TOTAL_FATALITIES,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    GROUPING(w.EVENT_TYPE) AS GROUPING_EVENT_TYPE,\n",
    "    GROUPING(w.REGION) AS GROUPING_REGION,\n",
    "    GROUPING(c.TITLE) AS GROUPING_WEBSITE_CATEGORY\n",
    "FROM\n",
    "    AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.FACTS f\n",
    "ON\n",
    "    w.STATE_FIPS = f.URLID -- Assuming URLID maps to STATE_FIPS\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.URLDIM u\n",
    "ON\n",
    "    f.URLID = u.ID\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.DMOZ_CATEGORIES c\n",
    "ON\n",
    "    u.THISDOMAIN = c.TOPIC\n",
    "GROUP BY GROUPING SETS (\n",
    "    (w.EVENT_TYPE, w.REGION, c.TITLE),\n",
    "    (w.EVENT_TYPE, w.REGION),\n",
    "    (w.EVENT_TYPE),\n",
    "    ()\n",
    ")\n",
    "HAVING\n",
    "    SUM(w.DAMAGE_PROPERTY) > 100000 OR\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) > 5\n",
    "ORDER BY\n",
    "    TOTAL_PROPERTY_DAMAGE DESC,\n",
    "    TOTAL_FATALITIES DESC,\n",
    "    TOTAL_QUERIES DESC;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DOMAIN_NAME</th>\n",
       "      <th>WEBSITE_TITLE</th>\n",
       "      <th>TOTAL_PROPERTY_DAMAGE</th>\n",
       "      <th>TOTAL_FATALITIES</th>\n",
       "      <th>TOTAL_QUERIES</th>\n",
       "      <th>GROUPING_EVENT_TYPE</th>\n",
       "      <th>GROUPING_REGION</th>\n",
       "      <th>GROUPING_DOMAIN_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hail</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>mybrotha</td>\n",
       "      <td>Mybrotha.com</td>\n",
       "      <td>3666000</td>\n",
       "      <td>0</td>\n",
       "      <td>3666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EVENT_TYPE    REGION DOMAIN_NAME WEBSITE_TITLE  TOTAL_PROPERTY_DAMAGE  \\\n",
       "13       Hail  Illinois    mybrotha  Mybrotha.com                3666000   \n",
       "\n",
       "    TOTAL_FATALITIES  TOTAL_QUERIES  GROUPING_EVENT_TYPE  GROUPING_REGION  \\\n",
       "13                 0           3666                    0                0   \n",
       "\n",
       "    GROUPING_DOMAIN_NAME  \n",
       "13                     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    u.TITLE AS WEBSITE_TITLE,\n",
    "    SUM(w.DAMAGE_PROPERTY) AS TOTAL_PROPERTY_DAMAGE,\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) AS TOTAL_FATALITIES,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    GROUPING(w.EVENT_TYPE) AS GROUPING_EVENT_TYPE,\n",
    "    GROUPING(w.REGION) AS GROUPING_REGION,\n",
    "    GROUPING(u.THISDOMAIN) AS GROUPING_DOMAIN_NAME\n",
    "FROM\n",
    "    AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.FACTS f\n",
    "ON\n",
    "    w.STATE_FIPS = f.URLID -- Assuming URLID maps to STATE_FIPS\n",
    "LEFT JOIN\n",
    "    AOL_SCHEMA.URLDIM u\n",
    "ON\n",
    "    f.URLID = u.ID\n",
    "GROUP BY GROUPING SETS (\n",
    "    (w.EVENT_TYPE, w.REGION, u.THISDOMAIN, u.TITLE),\n",
    "    (w.EVENT_TYPE, w.REGION, u.THISDOMAIN),\n",
    "    (w.EVENT_TYPE, w.REGION),\n",
    "    (w.EVENT_TYPE),\n",
    "    ()\n",
    ")\n",
    "HAVING\n",
    "    SUM(w.DAMAGE_PROPERTY) > 100000 OR\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) > 5\n",
    "ORDER BY\n",
    "    TOTAL_PROPERTY_DAMAGE DESC,\n",
    "    TOTAL_FATALITIES DESC,\n",
    "    TOTAL_QUERIES DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "# Assume df is the DataFrame containing the query results\n",
    "df = conn.export_to_pandas(query)\n",
    "filtered_df = df.dropna()\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       REGION         EVENT_TYPE       WEBSITE_TITLE  TOTAL_QUERIES  \\\n",
      "0         NaN                NaN                 NaN          82633   \n",
      "1         NaN               Hail                 NaN          37350   \n",
      "2         NaN  Thunderstorm Wind                 NaN          18939   \n",
      "3      Kansas               Hail                 NaN           8195   \n",
      "4      Kansas               Hail                 NaN           8195   \n",
      "5         NaN          High Wind                 NaN           5004   \n",
      "6   Tennessee               Hail                 NaN           4908   \n",
      "7   Tennessee               Hail                 NaN           4908   \n",
      "8   Tennessee  Thunderstorm Wind                 NaN           4056   \n",
      "9   Tennessee  Thunderstorm Wind                 NaN           4056   \n",
      "10   Illinois               Hail        Mybrotha.com           3666   \n",
      "11   Illinois               Hail                 NaN           3666   \n",
      "12        NaN         Heavy Snow                 NaN           3593   \n",
      "13     Oregon          High Wind                 NaN           2862   \n",
      "14     Oregon          High Wind                 NaN           2862   \n",
      "15        NaN            Tornado                 NaN           2732   \n",
      "16        NaN       Winter Storm                 NaN           2679   \n",
      "17    Indiana               Hail  Ellis County Press           2285   \n",
      "18    Indiana               Hail                 NaN           2285   \n",
      "19  Wisconsin               Hail    Kingdom Hearts 3           2160   \n",
      "\n",
      "    GROUPING_REGION  GROUPING_EVENT_TYPE  GROUPING_WEBSITE_TITLE  \n",
      "0                 1                    1                       1  \n",
      "1                 1                    0                       1  \n",
      "2                 1                    0                       1  \n",
      "3                 0                    0                       0  \n",
      "4                 0                    0                       1  \n",
      "5                 1                    0                       1  \n",
      "6                 0                    0                       0  \n",
      "7                 0                    0                       1  \n",
      "8                 0                    0                       0  \n",
      "9                 0                    0                       1  \n",
      "10                0                    0                       0  \n",
      "11                0                    0                       1  \n",
      "12                1                    0                       1  \n",
      "13                0                    0                       0  \n",
      "14                0                    0                       1  \n",
      "15                1                    0                       1  \n",
      "16                1                    0                       1  \n",
      "17                0                    0                       0  \n",
      "18                0                    0                       1  \n",
      "19                0                    0                       0  \n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    w.REGION,\n",
    "    w.EVENT_TYPE,\n",
    "    u.TITLE AS WEBSITE_TITLE,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    GROUPING(w.REGION) AS GROUPING_REGION,\n",
    "    GROUPING(w.EVENT_TYPE) AS GROUPING_EVENT_TYPE,\n",
    "    GROUPING(u.TITLE) AS GROUPING_WEBSITE_TITLE\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "GROUP BY GROUPING SETS (\n",
    "    (w.REGION, w.EVENT_TYPE, u.TITLE),\n",
    "    (w.REGION, w.EVENT_TYPE),\n",
    "    (w.EVENT_TYPE),\n",
    "    ()\n",
    ")\n",
    "ORDER BY TOTAL_QUERIES DESC\n",
    "LIMIT 20;\n",
    "\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    STATE_FIPS     REGION  WEBSITE_CATEGORY  TOTAL_PROPERTY_DAMAGE  \\\n",
      "0          NaN        NaN               NaN               82633000   \n",
      "1         20.0     Kansas               NaN               11946000   \n",
      "2         20.0        NaN               NaN               11946000   \n",
      "3         20.0        NaN               NaN               11946000   \n",
      "4         47.0  Tennessee               NaN               10092000   \n",
      "5         47.0        NaN               NaN               10092000   \n",
      "6         47.0        NaN               NaN               10092000   \n",
      "7         26.0   Michigan               NaN                7803000   \n",
      "8         26.0        NaN               NaN                7803000   \n",
      "9         26.0        NaN               NaN                7803000   \n",
      "10        17.0   Illinois               NaN                7266000   \n",
      "11        17.0        NaN               NaN                7266000   \n",
      "12        17.0        NaN               NaN                7266000   \n",
      "13        41.0     Oregon               NaN                5751000   \n",
      "14        41.0        NaN               NaN                5751000   \n",
      "15        41.0        NaN               NaN                5751000   \n",
      "16        18.0    Indiana               NaN                4150000   \n",
      "17        18.0        NaN               NaN                4150000   \n",
      "18        18.0        NaN               NaN                4150000   \n",
      "19        55.0  Wisconsin               NaN                3705000   \n",
      "\n",
      "    TOTAL_QUERIES  GROUPING_STATE_FIPS  GROUPING_WEBSITE_CATEGORY  \n",
      "0           82633                    1                          1  \n",
      "1           11946                    0                          0  \n",
      "2           11946                    0                          0  \n",
      "3           11946                    0                          1  \n",
      "4           10092                    0                          0  \n",
      "5           10092                    0                          0  \n",
      "6           10092                    0                          1  \n",
      "7            7803                    0                          0  \n",
      "8            7803                    0                          0  \n",
      "9            7803                    0                          1  \n",
      "10           7266                    0                          0  \n",
      "11           7266                    0                          0  \n",
      "12           7266                    0                          1  \n",
      "13           5751                    0                          0  \n",
      "14           5751                    0                          0  \n",
      "15           5751                    0                          1  \n",
      "16           4150                    0                          0  \n",
      "17           4150                    0                          0  \n",
      "18           4150                    0                          1  \n",
      "19           3705                    0                          0  \n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    w.STATE_FIPS,\n",
    "    w.REGION,\n",
    "    c.TITLE AS WEBSITE_CATEGORY,\n",
    "    SUM(w.DAMAGE_PROPERTY) AS TOTAL_PROPERTY_DAMAGE,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    GROUPING(w.STATE_FIPS) AS GROUPING_STATE_FIPS,\n",
    "    GROUPING(c.TITLE) AS GROUPING_WEBSITE_CATEGORY\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "LEFT JOIN AOL_SCHEMA.DMOZ_CATEGORIES c ON u.THISDOMAIN = REGEXP_SUBSTR(c.TOPIC, '[^/]+$', 1, 1)\n",
    "GROUP BY GROUPING SETS (\n",
    "    (w.STATE_FIPS, w.REGION, c.TITLE),\n",
    "    (w.STATE_FIPS, c.TITLE),\n",
    "    (w.STATE_FIPS),\n",
    "    ()\n",
    ")\n",
    "HAVING SUM(w.DAMAGE_PROPERTY) > 1000000\n",
    "ORDER BY TOTAL_PROPERTY_DAMAGE DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EVENT_TYPE      REGION  DEMOGRAPHIC_GROUP  TOTAL_FATALITIES  \\\n",
      "0       Tornado   Tennessee             444221               102   \n",
      "1      Wildfire       Texas             466967                12   \n",
      "2     High Surf      Oregon             518451                12   \n",
      "3   Flash Flood      Hawaii              84569                 7   \n",
      "4   Strong Wind  Washington             528758                 6   \n",
      "5     High Wind    Michigan             139958                 6   \n",
      "6     Avalanche  Washington             528758                 6   \n",
      "7       Tornado   Tennessee             519991                68   \n",
      "8     High Surf      Oregon             203495                 9   \n",
      "9       Tornado   Tennessee             189208                34   \n",
      "10      Tornado   Tennessee             486002                34   \n",
      "11      Tornado   Tennessee             359602                34   \n",
      "12      Tornado   Tennessee             649329                34   \n",
      "13      Tornado   Tennessee             180831                34   \n",
      "14      Tornado   Tennessee             594388                34   \n",
      "15      Tornado   Tennessee              62366                34   \n",
      "16    High Surf      Oregon             108892                 6   \n",
      "17    High Surf      Oregon             285085                 6   \n",
      "18    High Surf      Oregon             389494                 6   \n",
      "19      Tornado    Missouri             480380                13   \n",
      "\n",
      "    TOTAL_QUERIES  FATALITY_RANK  \n",
      "0              87              1  \n",
      "1              87              1  \n",
      "2              12              1  \n",
      "3              29              1  \n",
      "4              33              1  \n",
      "5              12              1  \n",
      "6               6              1  \n",
      "7              58              2  \n",
      "8               9              2  \n",
      "9              29              3  \n",
      "10             29              3  \n",
      "11             29              3  \n",
      "12             29              3  \n",
      "13             29              3  \n",
      "14             29              3  \n",
      "15             29              3  \n",
      "16              6              3  \n",
      "17              6              3  \n",
      "18              6              3  \n",
      "19            118             10  \n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    w.EVENT_TYPE,\n",
    "    w.REGION,\n",
    "    f.ANONID AS DEMOGRAPHIC_GROUP,\n",
    "    SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) AS TOTAL_FATALITIES,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    RANK() OVER (PARTITION BY w.EVENT_TYPE ORDER BY SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) DESC) AS FATALITY_RANK\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "GROUP BY w.EVENT_TYPE, w.REGION, f.ANONID\n",
    "HAVING SUM(w.DEATHS_DIRECT + w.DEATHS_INDIRECT) > 5\n",
    "ORDER BY FATALITY_RANK, TOTAL_FATALITIES DESC, TOTAL_QUERIES DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      REGION       DOMAIN_NAME  TOTAL_INJURIES  TOTAL_QUERIES  INJURY_RANK\n",
      "0     Kansas             crime             209          11946            1\n",
      "1  Tennessee    buildingtrades            3168          10092            1\n",
      "2   Michigan       lvbeethoven            1566           7803            1\n",
      "3   Illinois          mybrotha             384           7266            1\n",
      "4     Oregon        watsonrent              54           5751            1\n",
      "5    Indiana  elliscountypress              30           4150            1\n",
      "6  Wisconsin    kingdomhearts3             105           3705            1\n",
      "7   Kentucky          magelang             156           3308            1\n",
      "8    Alabama  darrellmansfield              48           2604            1\n",
      "9   Arkansas             mxram             219           1944            1\n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    w.REGION,\n",
    "    u.THISDOMAIN AS DOMAIN_NAME,\n",
    "    SUM(w.INJURIES_DIRECT + w.INJURIES_INDIRECT) AS TOTAL_INJURIES,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    RANK() OVER (PARTITION BY w.REGION ORDER BY SUM(w.INJURIES_DIRECT + w.INJURIES_INDIRECT) DESC) AS INJURY_RANK\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN AOL_SCHEMA.URLDIM u ON f.URLID = u.ID\n",
    "GROUP BY w.REGION, u.THISDOMAIN\n",
    "HAVING SUM(w.INJURIES_DIRECT + w.INJURIES_INDIRECT) > 10\n",
    "ORDER BY INJURY_RANK, TOTAL_QUERIES DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR_MONTH        EVENT_TYPE  TOTAL_QUERIES  TOTAL_PROPERTY_DAMAGE  \\\n",
      "0      2006-01               NaN           7059                7059000   \n",
      "1      2006-01         High Wind           2209                2209000   \n",
      "2      2006-01        Heavy Snow           1130                1130000   \n",
      "3      2006-01              Hail            567                 567000   \n",
      "4      2006-01      Winter Storm            510                 510000   \n",
      "..         ...               ...            ...                    ...   \n",
      "146    2006-05     Coastal Flood              5                   5000   \n",
      "147    2006-05   Cold/Wind Chill              2                   2000   \n",
      "148    2006-05  Marine High Wind              2                   2000   \n",
      "149    2006-05         Avalanche              1                   1000   \n",
      "150        NaN               NaN          82633               82633000   \n",
      "\n",
      "     GROUPING_MONTH  GROUPING_EVENT_TYPE  \n",
      "0                 0                    1  \n",
      "1                 0                    0  \n",
      "2                 0                    0  \n",
      "3                 0                    0  \n",
      "4                 0                    0  \n",
      "..              ...                  ...  \n",
      "146               0                    0  \n",
      "147               0                    0  \n",
      "148               0                    0  \n",
      "149               0                    0  \n",
      "150               1                    1  \n",
      "\n",
      "[151 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    TO_CHAR(w.BEGIN_DATE_TIME, 'YYYY-MM') AS YEAR_MONTH,\n",
    "    w.EVENT_TYPE,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    SUM(w.DAMAGE_PROPERTY) AS TOTAL_PROPERTY_DAMAGE,\n",
    "    GROUPING(TO_CHAR(w.BEGIN_DATE_TIME, 'YYYY-MM')) AS GROUPING_MONTH,\n",
    "    GROUPING(w.EVENT_TYPE) AS GROUPING_EVENT_TYPE\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "GROUP BY ROLLUP (\n",
    "    TO_CHAR(w.BEGIN_DATE_TIME, 'YYYY-MM'),\n",
    "    w.EVENT_TYPE\n",
    ")\n",
    "ORDER BY YEAR_MONTH ASC, TOTAL_QUERIES DESC;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EVENT_TYPE  QUERYID  TOTAL_QUERIES  TOTAL_CROP_DAMAGE  CROP_DAMAGE_RANK\n",
      "0      Drought  4522325             26         1600250000                 1\n",
      "1     Wildfire  4522325             87          139070000                 1\n",
      "2   Heavy Rain   371707             82           93020000                 1\n",
      "3        Flood   371707             66           84600000                 1\n",
      "4  Debris Flow   371707             24           40000000                 1\n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    w.EVENT_TYPE,\n",
    "    f.QUERYID,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    SUM(w.DAMAGE_CROPS) AS TOTAL_CROP_DAMAGE,\n",
    "    RANK() OVER (PARTITION BY w.EVENT_TYPE ORDER BY SUM(w.DAMAGE_CROPS) DESC) AS CROP_DAMAGE_RANK\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "GROUP BY w.EVENT_TYPE, f.QUERYID\n",
    "HAVING SUM(w.DAMAGE_CROPS) > 50000\n",
    "ORDER BY CROP_DAMAGE_RANK, TOTAL_CROP_DAMAGE DESC, TOTAL_QUERIES DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# # Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          EVENT_TYPE                 SEARCH_QUERY  TOTAL_QUERIES  \\\n",
      "0            Drought                fortunate son             26   \n",
      "1           Wildfire                fortunate son             87   \n",
      "2         Heavy Rain  www.larrywilliamsphotog.com             82   \n",
      "3              Flood  www.larrywilliamsphotog.com             66   \n",
      "4        Debris Flow  www.larrywilliamsphotog.com             24   \n",
      "5       Frost/Freeze  www.larrywilliamsphotog.com             32   \n",
      "6               Hail                 www.free4all            546   \n",
      "7            Tornado                       nastya             13   \n",
      "8  Thunderstorm Wind          beethoven biography            414   \n",
      "9        Strong Wind  www.larrywilliamsphotog.com             94   \n",
      "\n",
      "   TOTAL_CROP_DAMAGE  CROP_DAMAGE_RANK  \n",
      "0         1600250000                 1  \n",
      "1          139070000                 1  \n",
      "2           93020000                 1  \n",
      "3           84600000                 1  \n",
      "4           40000000                 1  \n",
      "5           23880000                 1  \n",
      "6           13200000                 1  \n",
      "7            1130000                 1  \n",
      "8             240000                 1  \n",
      "9             225000                 1  \n"
     ]
    }
   ],
   "source": [
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    w.EVENT_TYPE,\n",
    "    q.QUERY AS SEARCH_QUERY,\n",
    "    COUNT(f.QUERYID) AS TOTAL_QUERIES,\n",
    "    SUM(w.DAMAGE_CROPS) AS TOTAL_CROP_DAMAGE,\n",
    "    RANK() OVER (PARTITION BY w.EVENT_TYPE ORDER BY SUM(w.DAMAGE_CROPS) DESC) AS CROP_DAMAGE_RANK\n",
    "FROM AOL_SCHEMA.WEATHER_EVENTS w\n",
    "LEFT JOIN AOL_SCHEMA.FACTS f ON w.STATE_FIPS = f.URLID\n",
    "LEFT JOIN AOL_SCHEMA.QUERYDIM q ON f.QUERYID = q.ID  -- Replace QUERYID with the correct column in QUERYDIM\n",
    "GROUP BY w.EVENT_TYPE, q.QUERY\n",
    "HAVING SUM(w.DAMAGE_CROPS) > 50000\n",
    "ORDER BY CROP_DAMAGE_RANK, TOTAL_CROP_DAMAGE DESC, TOTAL_QUERIES DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(conn.export_to_pandas(query))\n",
    "# result = conn.execute(query)\n",
    "\n",
    "# Fetch and print the results\n",
    "# for row in result:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('QUERY', 'VARCHAR(5000) UTF8', 'TRUE', 'FALSE')\n",
      "('ID', 'DECIMAL(18,0)', 'TRUE', 'FALSE')\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "DESCRIBE AOL_SCHEMA.QUERYDIM;\n",
    "\"\"\"\n",
    "# print(conn.export_to_pandas(query))\n",
    "result = conn.execute(query)\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>WEBSITE_CATEGORY</th>\n",
       "      <th>TOTAL_PROPERTY_DAMAGE</th>\n",
       "      <th>TOTAL_FATALITIES</th>\n",
       "      <th>TOTAL_QUERIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EVENT_TYPE, REGION, WEBSITE_CATEGORY, TOTAL_PROPERTY_DAMAGE, TOTAL_FATALITIES, TOTAL_QUERIES]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the query and fetch results into a Pandas DataFrame\n",
    "df = conn.export_to_pandas(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
